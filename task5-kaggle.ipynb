{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2- Task 5: Kaggle Open-ended Competition\n",
    "\n",
    "Kaggle is a platform for predictive modelling and analytics competitions in which companies and researchers post data and statisticians and data miners compete to produce the best models for predicting and describing the data.\n",
    "\n",
    "If you don't have a Kaggle account, feel free to join at [www.kaggle.com](https://www.kaggle.com). To let the TAs do the grading more conveniently, please use Lionmail to join Kaggle and use UNI as your username.\n",
    "\n",
    "Visit the website for this competition to join: \n",
    "[https://www.kaggle.com/t/8dd419892b1c49a3afb0cea385a7e677](https://www.kaggle.com/t/8dd419892b1c49a3afb0cea385a7e677)\n",
    "\n",
    "Details about this in-class competition is shown on the website above. Please read carefully.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span>\n",
    "1. Train a custom model for the bottle dataset classification problem. You are free to use any methods taught in the class or found by yourself on the Internet (ALWAYS provide reference to the source). General training methods include:\n",
    "    * Dropout\n",
    "    * Batch normalization\n",
    "    * Early stopping\n",
    "    * l1-norm & l2-norm penalization\n",
    "2. You'll be given the test set to generate your predictions (70% public + 30% private, but you don't know which ones are public/private). Achieve 70% accuracy on the public test set. The accuracy will be shown on the public leaderboard once you submit your prediction .csv file. \n",
    "3. (A) Report your results on the Kaggle, for comparison with other students' optimization results (you should do this several times). (C) Save your best model, using BitBucket, at the same time when you (B) submit the homework files into Courseworks. See instructions below. \n",
    "\n",
    "__Hint__: You can start from what you implemented in task 4. Another classic classification model named 'VGG16' can also be easily implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Submission Details:\n",
    "There are three components to reporting the results of this task: \n",
    "\n",
    "**(A) Submission (possible several) of the .csv prediction file throught the Kaggle platform;**. You should start doing this VARY early, so that students can compare their work as they are making progress with model optimization.\n",
    "\n",
    "**(B) Editing and submitting the content of this Jupyter notebook, through Courseworks; **\n",
    "(i) The code for your CNN model and for the training function. The code should be stored in __./ecbm4040/neuralnets/kaggle.py__;\n",
    "(ii) Print out your training process and accuracy __within this notebook__;\n",
    "\n",
    "**(C) Submitting your best CNN model through instructor-owned private BitBucket repo.**\n",
    "\n",
    "**Description of (C):** \n",
    "For this task, you will be utilizing bitbucket to save your model for submission. Bitbucket provides Git code managment. For those who are not familiar with git operations, please check [Learn Git with Bitbucket Cloud](https://www.atlassian.com/git/tutorials/learn-git-with-bitbucket-cloud) as reference.\n",
    "**TAs will create a private Bitbucket repository for each student, with the write access. This repo will be owned by the instructors. Make sure to properly submit your model to that exact repository (submissions to your own private repository will not count)** Students need to populate the following file to provide instructors with bitbucket account information: https://docs.google.com/spreadsheets/d/1_7cZjyr34I2y-AD_0N5UaJ3ZnqdhYcvrdoTsYvOSd-g/edit#gid=0.\n",
    "\n",
    "<span style=\"color:red\">__Submission content:__ :</span>\n",
    "(i) Upload your best model with all the data output (for example, __MODEL.data-00000-of-00001, MODEL.meta, MODEL.index__) into the  BitBucket. Store your model in the folder named \"__KaggleModel__\" within the BitBucket repository. \n",
    "Remember to delete any intermediate results, **we only want your best model. Do not upload any data files**. The instructors will rerun the uploaded best model and verify against the score which you reported on the Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import imageio\n",
    "from ecbm4040.neuralnets.kaggle import training\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for label in range(5):\n",
    "    for pic in range(3000):\n",
    "        pic_idx = str(label*3000 + pic)\n",
    "        arr = imageio.imread('data/train_128/%s/%s.png'%(label,pic_idx)) \n",
    "        # X_train.append(arr)\n",
    "        X_train.append(arr[::4,::4])\n",
    "        Y_train.append(label)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_org = np.array(X_train)\n",
    "Y_org = np.array(Y_train)\n",
    "\n",
    "num_org = X_org.shape[0]\n",
    "train_proportion = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11250, 32, 32, 3)\n",
      "(11250,)\n"
     ]
    }
   ],
   "source": [
    "sample_idxs = np.random.choice(num_org, int(num_org*train_proportion))\n",
    "train_X = X_org[sample_idxs,:]\n",
    "train_Y = Y_org[sample_idxs]\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_X = X_org[-sample_idxs,:]\n",
    "val_Y = Y_org[-sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[60, 70]\n",
      "fc_units=[120, 100]\n",
      "conv_kernel_size=[6, 6]\n",
      "pooling_size=[2, 2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "***************************************************8\n",
      "Tensor(\"inputs/Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "(?, 32, 32, 3)\n",
      "True\n",
      "True\n",
      "3 3 True\n",
      "Pass0 (?, 32, 32, 60)\n",
      "Pass1 (?, 16, 16, 60)\n",
      "Pass2 (?, 16, 16, 60)\n",
      "***************************************************8\n",
      "Tensor(\"local_response_norm/LRN:0\", shape=(?, 16, 16, 60), dtype=float32)\n",
      "(?, 16, 16, 60)\n",
      "True\n",
      "True\n",
      "60 60 True\n",
      "Pass3 (?, 16, 16, 70)\n",
      "Pass4 (?, 8, 8, 70)\n",
      "Pass5 (?, 8, 8, 70)\n",
      "Pass6 (?, 120)\n",
      "number of batches for training: 107\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 48.82666666666667%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:200 accuracy: 63.973333333333336%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:300 accuracy: 68.32%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:400 accuracy: 69.54666666666667%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:500 accuracy: 71.40444444444444%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:600 accuracy: 72.50666666666666%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:800 accuracy: 75.5911111111111%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:900 accuracy: 76.76444444444445%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:1200 accuracy: 77.83111111111111%\n",
      "epoch 13 \n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:1400 accuracy: 78.85333333333332%\n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:1500 accuracy: 80.94222222222223%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:1800 accuracy: 81.6888888888889%\n",
      "epoch 18 \n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:2000 accuracy: 82.24888888888889%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:2100 accuracy: 83.18222222222222%\n",
      "Traning ends. The best valid accuracy is 83.18222222222222. Model named lenet_1509837508.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "training(train_X, train_Y, val_X, val_Y, \n",
    "         conv_featmap=[60,70],\n",
    "         fc_units=[120,100],\n",
    "         conv_kernel_size=[6,6],\n",
    "         pooling_size=[2,2],\n",
    "         l2_norm=0.01,\n",
    "         seed=235,\n",
    "         learning_rate=1e-2,\n",
    "         epoch=20,\n",
    "         batch_size=105,\n",
    "         verbose=False,\n",
    "         pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for pic in range(3500):\n",
    "    pic_idx = str(pic)\n",
    "    arr = imageio.imread('data/test_128/%s.png'%(pic_idx)) \n",
    "    X_test.append(arr[::4,::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/lenet_1509837508\n",
      "tf_input: inputs/Placeholder:0\n",
      "[<tf.Operation 'inputs/Placeholder' type=Placeholder>, <tf.Operation 'inputs/Placeholder_1' type=Placeholder>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv_layer_0/conv_kernel_0/Initializer/random_uniform' type=Add>, <tf.Operation 'conv_layer_0/conv_kernel_0' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_kernel_0/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_kernel_0/read' type=Identity>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform' type=Add>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/read' type=Identity>, <tf.Operation 'conv_layer_0/Conv2D' type=Conv2D>, <tf.Operation 'conv_layer_0/add' type=Add>, <tf.Operation 'conv_layer_0/Relu' type=Relu>, <tf.Operation 'conv_layer_0/conv_layer/0/kernel/tag' type=Const>, <tf.Operation 'conv_layer_0/conv_layer/0/kernel' type=HistogramSummary>, <tf.Operation 'conv_layer_0/conv_layer/0/bias/tag' type=Const>, <tf.Operation 'conv_layer_0/conv_layer/0/bias' type=HistogramSummary>, <tf.Operation 'max_pooling/MaxPool' type=MaxPool>, <tf.Operation 'local_response_norm/LRN' type=LRN>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv_layer_1/conv_kernel_1/Initializer/random_uniform' type=Add>, <tf.Operation 'conv_layer_1/conv_kernel_1' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_kernel_1/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_kernel_1/read' type=Identity>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Initializer/random_uniform' type=Add>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/read' type=Identity>, <tf.Operation 'conv_layer_1/Conv2D' type=Conv2D>, <tf.Operation 'conv_layer_1/add' type=Add>, <tf.Operation 'conv_layer_1/Relu' type=Relu>, <tf.Operation 'conv_layer_1/conv_layer/1/kernel/tag' type=Const>, <tf.Operation 'conv_layer_1/conv_layer/1/kernel' type=HistogramSummary>, <tf.Operation 'conv_layer_1/conv_layer/1/bias/tag' type=Const>, <tf.Operation 'conv_layer_1/conv_layer/1/bias' type=HistogramSummary>, <tf.Operation 'max_pooling_1/MaxPool' type=MaxPool>, <tf.Operation 'local_response_norm_1/LRN' type=LRN>, <tf.Operation 'Reshape/shape' type=Const>, <tf.Operation 'Reshape' type=Reshape>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/min' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/max' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'fc_layer_0/fc_kernel_0/Initializer/random_uniform' type=Add>, <tf.Operation 'fc_layer_0/fc_kernel_0' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel_0/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel_0/read' type=Identity>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/min' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/max' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform' type=Add>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/read' type=Identity>, <tf.Operation 'fc_layer_0/MatMul' type=MatMul>, <tf.Operation 'fc_layer_0/Add' type=Add>, <tf.Operation 'fc_layer_0/Relu' type=Relu>, <tf.Operation 'fc_layer_0/fc_layer/0/kernel/tag' type=Const>, <tf.Operation 'fc_layer_0/fc_layer/0/kernel' type=HistogramSummary>, <tf.Operation 'fc_layer_0/fc_layer/0/bias/tag' type=Const>, <tf.Operation 'fc_layer_0/fc_layer/0/bias' type=HistogramSummary>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/min' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/max' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'fc_layer_1/fc_kernel_1/Initializer/random_uniform' type=Add>, <tf.Operation 'fc_layer_1/fc_kernel_1' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel_1/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel_1/read' type=Identity>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/min' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/max' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform' type=Add>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/read' type=Identity>, <tf.Operation 'fc_layer_1/MatMul' type=MatMul>, <tf.Operation 'fc_layer_1/Add' type=Add>, <tf.Operation 'fc_layer_1/fc_layer/1/kernel/tag' type=Const>, <tf.Operation 'fc_layer_1/fc_layer/1/kernel' type=HistogramSummary>, <tf.Operation 'fc_layer_1/fc_layer/1/bias/tag' type=Const>, <tf.Operation 'fc_layer_1/fc_layer/1/bias' type=HistogramSummary>, <tf.Operation 'loss/norm/mul' type=Mul>, <tf.Operation 'loss/norm/Const' type=Const>, <tf.Operation 'loss/norm/Sum' type=Sum>, <tf.Operation 'loss/norm/Sqrt' type=Sqrt>, <tf.Operation 'loss/norm/Squeeze' type=Squeeze>, <tf.Operation 'loss/norm_1/mul' type=Mul>, <tf.Operation 'loss/norm_1/Const' type=Const>, <tf.Operation 'loss/norm_1/Sum' type=Sum>, <tf.Operation 'loss/norm_1/Sqrt' type=Sqrt>, <tf.Operation 'loss/norm_1/Squeeze' type=Squeeze>, <tf.Operation 'loss/Rank/packed' type=Pack>, <tf.Operation 'loss/Rank' type=Const>, <tf.Operation 'loss/range/start' type=Const>, <tf.Operation 'loss/range/delta' type=Const>, <tf.Operation 'loss/range' type=Range>, <tf.Operation 'loss/Sum/input' type=Pack>, <tf.Operation 'loss/Sum' type=Sum>, <tf.Operation 'loss/norm_2/mul' type=Mul>, <tf.Operation 'loss/norm_2/Sum/reduction_indices' type=Const>, <tf.Operation 'loss/norm_2/Sum' type=Sum>, <tf.Operation 'loss/norm_2/Sqrt' type=Sqrt>, <tf.Operation 'loss/norm_2/Squeeze' type=Squeeze>, <tf.Operation 'loss/Rank_1/packed' type=Pack>, <tf.Operation 'loss/Rank_1' type=Const>, <tf.Operation 'loss/range_1/start' type=Const>, <tf.Operation 'loss/range_1/delta' type=Const>, <tf.Operation 'loss/range_1' type=Range>, <tf.Operation 'loss/Sum_1/input' type=Pack>, <tf.Operation 'loss/Sum_1' type=Sum>, <tf.Operation 'loss/add' type=Add>, <tf.Operation 'loss/one_hot/on_value' type=Const>, <tf.Operation 'loss/one_hot/off_value' type=Const>, <tf.Operation 'loss/one_hot/depth' type=Const>, <tf.Operation 'loss/one_hot' type=OneHot>, <tf.Operation 'loss/Rank_2' type=Const>, <tf.Operation 'loss/Shape' type=Shape>, <tf.Operation 'loss/Rank_3' type=Const>, <tf.Operation 'loss/Shape_1' type=Shape>, <tf.Operation 'loss/Sub/y' type=Const>, <tf.Operation 'loss/Sub' type=Sub>, <tf.Operation 'loss/Slice/begin' type=Pack>, <tf.Operation 'loss/Slice/size' type=Const>, <tf.Operation 'loss/Slice' type=Slice>, <tf.Operation 'loss/concat/values_0' type=Const>, <tf.Operation 'loss/concat/axis' type=Const>, <tf.Operation 'loss/concat' type=ConcatV2>, <tf.Operation 'loss/Reshape' type=Reshape>, <tf.Operation 'loss/Rank_4' type=Const>, <tf.Operation 'loss/Shape_2' type=Shape>, <tf.Operation 'loss/Sub_1/y' type=Const>, <tf.Operation 'loss/Sub_1' type=Sub>, <tf.Operation 'loss/Slice_1/begin' type=Pack>, <tf.Operation 'loss/Slice_1/size' type=Const>, <tf.Operation 'loss/Slice_1' type=Slice>, <tf.Operation 'loss/concat_1/values_0' type=Const>, <tf.Operation 'loss/concat_1/axis' type=Const>, <tf.Operation 'loss/concat_1' type=ConcatV2>, <tf.Operation 'loss/Reshape_1' type=Reshape>, <tf.Operation 'loss/SoftmaxCrossEntropyWithLogits' type=SoftmaxCrossEntropyWithLogits>, <tf.Operation 'loss/Sub_2/y' type=Const>, <tf.Operation 'loss/Sub_2' type=Sub>, <tf.Operation 'loss/Slice_2/begin' type=Const>, <tf.Operation 'loss/Slice_2/size' type=Pack>, <tf.Operation 'loss/Slice_2' type=Slice>, <tf.Operation 'loss/Reshape_2' type=Reshape>, <tf.Operation 'loss/Const' type=Const>, <tf.Operation 'loss/cross_entropy' type=Mean>, <tf.Operation 'loss/mul/x' type=Const>, <tf.Operation 'loss/mul' type=Mul>, <tf.Operation 'loss/loss' type=Add>, <tf.Operation 'loss/LeNet_loss/tags' type=Const>, <tf.Operation 'loss/LeNet_loss' type=ScalarSummary>, <tf.Operation 'train_step/gradients/Shape' type=Const>, <tf.Operation 'train_step/gradients/Const' type=Const>, <tf.Operation 'train_step/gradients/Fill' type=Fill>, <tf.Operation 'train_step/gradients/loss/loss_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/loss_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/loss_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/loss_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/loss_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/loss_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/loss_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/loss_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/loss_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/loss_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Reshape/shape' type=Const>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Shape_1' type=Shape>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Shape_2' type=Const>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Const' type=Const>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Prod' type=Prod>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Const_1' type=Const>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Prod_1' type=Prod>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Maximum/y' type=Const>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Maximum' type=Maximum>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/floordiv' type=FloorDiv>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/Cast' type=Cast>, <tf.Operation 'train_step/gradients/loss/cross_entropy_grad/truediv' type=RealDiv>, <tf.Operation 'train_step/gradients/loss/mul_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/mul_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/mul_grad/mul' type=Mul>, <tf.Operation 'train_step/gradients/loss/mul_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/mul_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/mul_grad/mul_1' type=Mul>, <tf.Operation 'train_step/gradients/loss/mul_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/mul_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/mul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/mul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/mul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/Reshape_2_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/loss/Reshape_2_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/add_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/add_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/add_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/add_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/add_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/add_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/zeros_like' type=ZerosLike>, <tf.Operation 'train_step/gradients/loss/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>, <tf.Operation 'train_step/gradients/loss/SoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>, <tf.Operation 'train_step/gradients/loss/SoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Size' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/add' type=Add>, <tf.Operation 'train_step/gradients/loss/Sum_grad/mod' type=FloorMod>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/range/start' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/range/delta' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/range' type=Range>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Fill/value' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Fill' type=Fill>, <tf.Operation 'train_step/gradients/loss/Sum_grad/DynamicStitch' type=DynamicStitch>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Maximum/y' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Maximum' type=Maximum>, <tf.Operation 'train_step/gradients/loss/Sum_grad/floordiv' type=FloorDiv>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/Sum_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Size' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/add' type=Add>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/mod' type=FloorMod>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/range/start' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/range/delta' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/range' type=Range>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Fill/value' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Fill' type=Fill>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/DynamicStitch' type=DynamicStitch>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Maximum/y' type=Const>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Maximum' type=Maximum>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/floordiv' type=FloorDiv>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/Sum_1_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/loss/Reshape_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/loss/Reshape_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/Sum/input_grad/unstack' type=Unpack>, <tf.Operation 'train_step/gradients/loss/Sum/input_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/Sum/input_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/Sum/input_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/Sum_1/input_grad/unstack' type=Unpack>, <tf.Operation 'train_step/gradients/loss/norm/Squeeze_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm/Squeeze_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_1/Squeeze_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_1/Squeeze_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_2/Squeeze_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Squeeze_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm/Sqrt_grad/SqrtGrad' type=SqrtGrad>, <tf.Operation 'train_step/gradients/loss/norm_1/Sqrt_grad/SqrtGrad' type=SqrtGrad>, <tf.Operation 'train_step/gradients/loss/norm_2/Sqrt_grad/SqrtGrad' type=SqrtGrad>, <tf.Operation 'train_step/gradients/loss/norm/Sum_grad/Reshape/shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm/Sum_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm/Sum_grad/Tile/multiples' type=Const>, <tf.Operation 'train_step/gradients/loss/norm/Sum_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/loss/norm_1/Sum_grad/Reshape/shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_1/Sum_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_1/Sum_grad/Tile/multiples' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_1/Sum_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Size' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/add' type=Add>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/mod' type=FloorMod>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/range/start' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/range/delta' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/range' type=Range>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Fill/value' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Fill' type=Fill>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/DynamicStitch' type=DynamicStitch>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Maximum/y' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Maximum' type=Maximum>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/floordiv' type=FloorDiv>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_2/Sum_grad/Tile' type=Tile>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/mul' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/mul_1' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm/mul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/mul' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/mul_1' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Shape' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/mul' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/mul_1' type=Mul>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_1/MatMul_grad/MatMul' type=MatMul>, <tf.Operation 'train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1' type=MatMul>, <tf.Operation 'train_step/gradients/fc_layer_1/MatMul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_0/Relu_grad/ReluGrad' type=ReluGrad>, <tf.Operation 'train_step/gradients/AddN' type=AddN>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_0/MatMul_grad/MatMul' type=MatMul>, <tf.Operation 'train_step/gradients/fc_layer_0/MatMul_grad/MatMul_1' type=MatMul>, <tf.Operation 'train_step/gradients/fc_layer_0/MatMul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/Reshape_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/Reshape_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/AddN_1' type=AddN>, <tf.Operation 'train_step/gradients/max_pooling_1/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'train_step/gradients/conv_layer_1/Relu_grad/ReluGrad' type=ReluGrad>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_1/add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_1/Conv2D_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/local_response_norm/LRN_grad/LRNGrad' type=LRNGrad>, <tf.Operation 'train_step/gradients/max_pooling/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'train_step/gradients/conv_layer_0/Relu_grad/ReluGrad' type=ReluGrad>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Sum' type=Sum>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Reshape' type=Reshape>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Sum_1' type=Sum>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/Reshape_1' type=Reshape>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/Shape' type=Shape>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/Shape_1' type=Const>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'train_step/gradients/conv_layer_0/Conv2D_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'train_step/gradients/AddN_2' type=AddN>, <tf.Operation 'train_step/beta1_power/initial_value' type=Const>, <tf.Operation 'train_step/beta1_power' type=VariableV2>, <tf.Operation 'train_step/beta1_power/Assign' type=Assign>, <tf.Operation 'train_step/beta1_power/read' type=Identity>, <tf.Operation 'train_step/beta2_power/initial_value' type=Const>, <tf.Operation 'train_step/beta2_power' type=VariableV2>, <tf.Operation 'train_step/beta2_power/Assign' type=Assign>, <tf.Operation 'train_step/beta2_power/read' type=Identity>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam/read' type=Identity>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam_1' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_kernel_0/Adam_1/read' type=Identity>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam/read' type=Identity>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam_1' type=VariableV2>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_layer_0/conv_bias/conv_bias_0/Adam_1/read' type=Identity>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam/read' type=Identity>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam_1' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_kernel_1/Adam_1/read' type=Identity>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam/read' type=Identity>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam_1' type=VariableV2>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_layer_1/conv_bias/conv_bias_1/Adam_1/read' type=Identity>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam/read' type=Identity>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam_1' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam_1/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel_0/Adam_1/read' type=Identity>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam/read' type=Identity>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam_1' type=VariableV2>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam_1/Assign' type=Assign>, <tf.Operation 'fc_layer_0/fc_kernel/fc_bias_0/Adam_1/read' type=Identity>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam/read' type=Identity>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam_1' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam_1/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel_1/Adam_1/read' type=Identity>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam/read' type=Identity>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam_1' type=VariableV2>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam_1/Assign' type=Assign>, <tf.Operation 'fc_layer_1/fc_kernel/fc_bias_1/Adam_1/read' type=Identity>, <tf.Operation 'train_step/Adam/learning_rate' type=Const>, <tf.Operation 'train_step/Adam/beta1' type=Const>, <tf.Operation 'train_step/Adam/beta2' type=Const>, <tf.Operation 'train_step/Adam/epsilon' type=Const>, <tf.Operation 'train_step/Adam/update_conv_layer_0/conv_kernel_0/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_conv_layer_0/conv_bias/conv_bias_0/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_conv_layer_1/conv_kernel_1/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_conv_layer_1/conv_bias/conv_bias_1/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_fc_layer_0/fc_kernel_0/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_fc_layer_0/fc_kernel/fc_bias_0/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_fc_layer_1/fc_kernel_1/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/update_fc_layer_1/fc_kernel/fc_bias_1/ApplyAdam' type=ApplyAdam>, <tf.Operation 'train_step/Adam/mul' type=Mul>, <tf.Operation 'train_step/Adam/Assign' type=Assign>, <tf.Operation 'train_step/Adam/mul_1' type=Mul>, <tf.Operation 'train_step/Adam/Assign_1' type=Assign>, <tf.Operation 'train_step/Adam' type=NoOp>, <tf.Operation 'evaluate/ArgMax/dimension' type=Const>, <tf.Operation 'evaluate/ArgMax' type=ArgMax>, <tf.Operation 'evaluate/sub' type=Sub>, <tf.Operation 'evaluate/error_num/NotEqual/y' type=Const>, <tf.Operation 'evaluate/error_num/NotEqual' type=NotEqual>, <tf.Operation 'evaluate/error_num/ToInt64' type=Cast>, <tf.Operation 'evaluate/error_num/Const' type=Const>, <tf.Operation 'evaluate/error_num/Sum' type=Sum>, <tf.Operation 'evaluate/LeNet_error_num/tags' type=Const>, <tf.Operation 'evaluate/LeNet_error_num' type=ScalarSummary>, <tf.Operation 'Merge/MergeSummary' type=MergeSummary>, <tf.Operation 'save/Const' type=Const>, <tf.Operation 'save/SaveV2/tensor_names' type=Const>, <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>, <tf.Operation 'save/SaveV2' type=SaveV2>, <tf.Operation 'save/control_dependency' type=Identity>, <tf.Operation 'save/RestoreV2/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2' type=RestoreV2>, <tf.Operation 'save/Assign' type=Assign>, <tf.Operation 'save/RestoreV2_1/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_1/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_1' type=RestoreV2>, <tf.Operation 'save/Assign_1' type=Assign>, <tf.Operation 'save/RestoreV2_2/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_2/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_2' type=RestoreV2>, <tf.Operation 'save/Assign_2' type=Assign>, <tf.Operation 'save/RestoreV2_3/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_3/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_3' type=RestoreV2>, <tf.Operation 'save/Assign_3' type=Assign>, <tf.Operation 'save/RestoreV2_4/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_4/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_4' type=RestoreV2>, <tf.Operation 'save/Assign_4' type=Assign>, <tf.Operation 'save/RestoreV2_5/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_5/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_5' type=RestoreV2>, <tf.Operation 'save/Assign_5' type=Assign>, <tf.Operation 'save/RestoreV2_6/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_6/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_6' type=RestoreV2>, <tf.Operation 'save/Assign_6' type=Assign>, <tf.Operation 'save/RestoreV2_7/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_7/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_7' type=RestoreV2>, <tf.Operation 'save/Assign_7' type=Assign>, <tf.Operation 'save/RestoreV2_8/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_8/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_8' type=RestoreV2>, <tf.Operation 'save/Assign_8' type=Assign>, <tf.Operation 'save/RestoreV2_9/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_9/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_9' type=RestoreV2>, <tf.Operation 'save/Assign_9' type=Assign>, <tf.Operation 'save/RestoreV2_10/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_10/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_10' type=RestoreV2>, <tf.Operation 'save/Assign_10' type=Assign>, <tf.Operation 'save/RestoreV2_11/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_11/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_11' type=RestoreV2>, <tf.Operation 'save/Assign_11' type=Assign>, <tf.Operation 'save/RestoreV2_12/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_12/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_12' type=RestoreV2>, <tf.Operation 'save/Assign_12' type=Assign>, <tf.Operation 'save/RestoreV2_13/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_13/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_13' type=RestoreV2>, <tf.Operation 'save/Assign_13' type=Assign>, <tf.Operation 'save/RestoreV2_14/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_14/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_14' type=RestoreV2>, <tf.Operation 'save/Assign_14' type=Assign>, <tf.Operation 'save/RestoreV2_15/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_15/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_15' type=RestoreV2>, <tf.Operation 'save/Assign_15' type=Assign>, <tf.Operation 'save/RestoreV2_16/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_16/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_16' type=RestoreV2>, <tf.Operation 'save/Assign_16' type=Assign>, <tf.Operation 'save/RestoreV2_17/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_17/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_17' type=RestoreV2>, <tf.Operation 'save/Assign_17' type=Assign>, <tf.Operation 'save/RestoreV2_18/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_18/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_18' type=RestoreV2>, <tf.Operation 'save/Assign_18' type=Assign>, <tf.Operation 'save/RestoreV2_19/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_19/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_19' type=RestoreV2>, <tf.Operation 'save/Assign_19' type=Assign>, <tf.Operation 'save/RestoreV2_20/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_20/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_20' type=RestoreV2>, <tf.Operation 'save/Assign_20' type=Assign>, <tf.Operation 'save/RestoreV2_21/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_21/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_21' type=RestoreV2>, <tf.Operation 'save/Assign_21' type=Assign>, <tf.Operation 'save/RestoreV2_22/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_22/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_22' type=RestoreV2>, <tf.Operation 'save/Assign_22' type=Assign>, <tf.Operation 'save/RestoreV2_23/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_23/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_23' type=RestoreV2>, <tf.Operation 'save/Assign_23' type=Assign>, <tf.Operation 'save/RestoreV2_24/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_24/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_24' type=RestoreV2>, <tf.Operation 'save/Assign_24' type=Assign>, <tf.Operation 'save/RestoreV2_25/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_25/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_25' type=RestoreV2>, <tf.Operation 'save/Assign_25' type=Assign>, <tf.Operation 'save/restore_all' type=NoOp>, <tf.Operation 'init' type=NoOp>]\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.kaggle import predict\n",
    "tf.reset_default_graph()\n",
    "kaggle_result = predict(X_test,\"lenet_1509837508.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .csv file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code snippet can be used to generate your prediction .csv file.\n",
    "import csv\n",
    "with open('predicted.csv','w',newline='') as csvfile:\n",
    "    fieldnames = ['Id','label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()    \n",
    "    for index,l in enumerate(kaggle_result):\n",
    "        filename = str(index)+'.png'\n",
    "        label = str(l)\n",
    "        writer.writerow({'Id': filename, 'label': label})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
